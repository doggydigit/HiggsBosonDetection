{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import functions in scripts\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../scripts'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "np.set_printoptions(suppress=True)\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "targets, traindata, ids = load_csv_data(\"../data/train.csv\",False)\n",
    "nr_traindata, nr_columns = traindata.shape\n",
    "print(traindata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/train.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    headers = next(reader)\n",
    "headers = np.array(headers[2:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation = np.corrcoef(np.c_[traindata, targets], rowvar = False)\n",
    "plot_corr_matrix(correlation, np.append(headers,'target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ind, corr in enumerate(correlation):\n",
    "    t = np.sort(corr)\n",
    "    print(t[:2], t[ -2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_hists(targets, traindata, headers):\n",
    "    sns.distplot(targets)\n",
    "\n",
    "    for i, header in enumerate(headers):\n",
    "        f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                        gridspec_kw={\"height_ratios\": (.20, .80)}, figsize=(10,6))\n",
    "\n",
    "        sns.boxplot(traindata[:,i], ax=ax_box)\n",
    "        sns.distplot(traindata[:,i], ax=ax_hist, label= header)\n",
    "\n",
    "        ax_box.set(yticks=[])\n",
    "        ax_hist.set(xlabel=header)\n",
    "        sns.despine(ax=ax_hist)\n",
    "        sns.despine(ax=ax_box, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert_median_for_nan(traindata)\n",
    "jet0, jet1, jet2, jet3, y1, y2, y3, y4 = split_data_by_jet_num(traindata, targets)\n",
    "jet0, _, _ = standardize(jet0)\n",
    "jet1, _, _ = standardize(jet1)\n",
    "jet2, _, _ = standardize(jet2)\n",
    "jet3, _, _ = standardize(jet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build_poly() missing 1 required positional argument: 'degree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2d2ae98abbf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minsert_median_for_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: build_poly() missing 1 required positional argument: 'degree'"
     ]
    }
   ],
   "source": [
    "insert_median_for_nan(traindata)\n",
    "traindata = build_poly(traindata, 4)\n",
    "traindata, _, _ = standardize(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_ridge, loss = ridge_regression(targets, train, lambda_ = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validation_demo(x,y):\n",
    "    seed = 54\n",
    "    #degree = 3\n",
    "    k_fold = 10\n",
    "    lambdas = np.logspace(-7, -4, 20)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = np.zeros(len(lambdas))\n",
    "    rmse_te = np.zeros(len(lambdas))\n",
    "    \n",
    "    \n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation: TODO\n",
    "    # *************************************************** \n",
    "    for ind, lambda_ in enumerate(lambdas): \n",
    "        print(ind, lambda_)\n",
    "        rmse_tr[ind], rmse_te[ind] = cross_validation(y, x, k_indices, k_fold, lambda_, \"linear\",\n",
    "                                                      1000000, gamma = 0.000001)\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1e-07\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-69421380fff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_validation_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-bcc96498aad2>\u001b[0m in \u001b[0;36mcross_validation_demo\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         rmse_tr[ind], rmse_te[ind] = cross_validation(y, x, k_indices, k_fold, lambda_, \"linear\",\n\u001b[0;32m---> 20\u001b[0;31m                                                       1000000, gamma = 0.000001)\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcross_validation_visualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/adam/EPFL_courses/Machine_Learning-2017/HiggsBosonDetection/scripts/implementations.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k, lambda_, model_type, max_iters, gamma)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_validation_demo(train, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Training Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights_ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d946b0be3c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_ridge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'weights_ridge' is not defined"
     ]
    }
   ],
   "source": [
    "train_predictions = predict_labels(weights_ridge, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the evaluation metric, we use simple classification accuracy (percentage of correct predictions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good predictions after multiplication will have positive value\n",
    "measure = train_predictions*targets\n",
    "num_of_good_predictions = measure[measure > 0].sum()\n",
    "accuracy = num_of_good_predictions/nr_traindata\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_targets, test_data, test_ids = load_csv_data(\"../data/test.csv\",False)\n",
    "nr_testdata, nr_testcolumns = test_data.shape\n",
    "test_features = white_cubic_features(test_data,nr_testcolumns,nr_testdata)\n",
    "test_predictions = predict_labels(weights, test_features)\n",
    "create_csv_submission(test_ids, test_predictions, \"Kozak_Nurmi_Tsai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
